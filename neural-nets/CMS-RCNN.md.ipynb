{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper\n",
    "\n",
    "* **Title**: CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection\n",
    "* **Authors**: Chenchen Zhu, Yutong Zheng, Khoa Luu, Marios Savvides\n",
    "* **Link**: http://arxiv.org/abs/1606.05413v1\n",
    "* **Tags**: Neural Network, face\n",
    "* **Year**: 2016\n",
    "\n",
    "# Summary\n",
    "\n",
    "* What\n",
    "  * They describe a model to locate faces in images.\n",
    "  * Their model uses information from suspected face regions *and* from the corresponding suspected body regions to classify whether a region contains a face.\n",
    "  * The intuition is, that seeing the region around the face (specifically where the body should be) can help in estimating whether a suspected face is really a face (e.g. it might also be part of a painting, statue or doll).\n",
    "\n",
    "* How\n",
    "  * Their whole model is called \"CMS-RCNN\" (Contextual Multi-Scale Region-CNN).\n",
    "  * It is based on the \"Faster R-CNN\" architecture.\n",
    "  * It uses the VGG network.\n",
    "  * Subparts of their model are: MS-RPN, CMS-CNN.\n",
    "  * MS-RPN finds candidate face regions. CMS-CNN refines their bounding boxes and classifies them (face / not face).\n",
    "  * **MS-RPN** (Multi-Scale Region Proposal Network)\n",
    "    * \"Looks\" at the feature maps of the network (VGG) at multiple scales (i.e. before/after pooling layers) and suggests regions for possible faces.\n",
    "    * Steps:\n",
    "      * Feed an image through the VGG network.\n",
    "      * Extract the feature maps of the three last convolutions that are before a pooling layer.\n",
    "      * Pool these feature maps so that they have the same heights and widths.\n",
    "      * Apply L2 normalization to each feature map so that they all have the same scale.\n",
    "      * Apply a 1x1 convolution to merge them to one feature map.\n",
    "      * Regress face bounding boxes from that feature map according to the Faster R-CNN technique.\n",
    "  * **CMS-CNN** (Contextual Multi-Scale CNN):\n",
    "    * \"Looks\" at feature maps of face candidates found by MS-RPN and classifies whether these regions contains faces.\n",
    "    * It also uses the same multi-scale technique (i.e. take feature maps from convs before pooling layers).\n",
    "    * It uses some area around these face regions as additional information (suspected regions of bodies).\n",
    "    * Steps:\n",
    "      * Receive face candidate regions from MS-RPN.\n",
    "      * Do per candidate region:\n",
    "        * Calculate the suspected coordinates of the body (only based on the x/y-position and size of the face region, i.e. not learned).\n",
    "        * Extract the feature maps of the *face* region (at multiple scales) and apply RoI-Pooling to it (i.e. convert to a fixed height and width).\n",
    "        * Extract the feature maps of the *body* region (at multiple scales) and apply RoI-Pooling to it (i.e. convert to a fixed height and width).\n",
    "        * L2-normalize each feature map.\n",
    "        * Concatenate the (RoI-pooled and normalized) feature maps of the face (at multiple scales) with each other (creates one tensor).\n",
    "        * Concatenate the (RoI-pooled and normalized) feature maps of the body (at multiple scales) with each other (creates another tensor).\n",
    "        * Apply a 1x1 convolution to the face tensor.\n",
    "        * Apply a 1x1 convolution to the body tensor.\n",
    "        * Apply two fully connected layers to the face tensor, creating a vector.\n",
    "        * Apply two fully connected layers to the body tensor, creating a vector.\n",
    "        * Concatenate both vectors.\n",
    "        * Based on that vector, make a classification of whether it is really a face.\n",
    "        * Based on that vector, make a regression of the face's final bounding box coordinates and dimensions.\n",
    "  * Note: They use in both networks the multi-scale approach in order to be able to find small or tiny faces. Otherwise, after pooling these small faces would be hard or impossible to detect.\n",
    "\n",
    "* Results\n",
    "  * Adding context to the classification (i.e. the body regions) empirically improves the results.\n",
    "  * Their model achieves the highest recall rate on FDDB compared to other models. However, it has lower recall if only very few false positives are accepted.\n",
    "  * FDDB ROC curves (theirs is bold red):\n",
    "    * ![FDDB results](images/CMS-RCNN__fddb.jpg?raw=true \"FDDB results\")\n",
    "  * Example results on FDDB:\n",
    "    * ![FDDB examples](images/CMS-RCNN__examples.jpg?raw=true \"FDDB examples\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
