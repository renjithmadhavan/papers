{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper\n",
    "\n",
    "* **Title**: InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\n",
    "* **Authors**: Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel\n",
    "* **Link**: https://arxiv.org/abs/1606.03657\n",
    "* **Tags**: Neural Network, GAN\n",
    "* **Year**: 2016\n",
    "\n",
    "# Summary\n",
    "\n",
    "* What\n",
    "  * Usually GANs transform a noise vector `z` into images. `z` might be sampled from a normal or uniform distribution.\n",
    "  * The effect of this is, that the components in `z` are deeply entangled.\n",
    "    * Changing single components has hardly any influence on the generated images. One has to change multiple components to affect the image.\n",
    "    * The components end up not being interpretable. Ideally one would like to have meaningful components, e.g. for human faces one that controls the hair length and a categorical one that controls the eye color.\n",
    "  * They suggest a change to GANs based on Mutual Information, which leads to interpretable components.\n",
    "    * E.g. for MNIST a component that controls the stroke thickness and a categorical component that controls the digit identity (1, 2, 3, ...).\n",
    "    * These components are learned in a (mostly) unsupervised fashion.\n",
    "\n",
    "* How\n",
    "  * The latent code `c`\n",
    "    * \"Normal\" GANs parameterize the generator as `G(z)`, i.e. G receives a noise vector and transforms it into an image.\n",
    "    * This is changed to `G(z, c)`, i.e. G now receives a noise vector `z` and a latent code `c` and transforms both into an image.\n",
    "    * `c` can contain multiple variables following different distributions, e.g. in MNIST a categorical variable for the digit identity and a gaussian one for the stroke thickness.\n",
    "  * Mutual Information\n",
    "    * If using a latent code via `G(z, c)`, nothing forces the generator to actually use `c`. It can easily ignore it and just deteriorate to `G(z)`.\n",
    "    * To prevent that, they force G to generate images `x` in a way that `c` must be recoverable. So, if you have an image `x` you must be able to reliable tell which latent code `c` it has, which means that G must use `c` in a meaningful way.\n",
    "    * This relationship can be expressed with mutual information, i.e. the mutual information between `x` and `c` must be high.\n",
    "      * The mutual information between two variables X and Y is defined as `I(X; Y) = entropy(X) - entropy(X|Y) = entropy(Y) - entropy(Y|X)`.\n",
    "      * If the mutual information between X and Y is high, then knowing Y helps you to decently predict the value of X (and the other way round).\n",
    "      * If the mutual information between X and Y is low, then knowing Y doesn't tell you much about the value of X (and the other way round).\n",
    "    * The new GAN loss becomes `old loss - lambda * I(G(z, c); c)`, i.e. the higher the mutual information, the lower the result of the loss function.\n",
    "  * Variational Mutual Information Maximization\n",
    "    * In order to minimize `I(G(z, c); c)`, one has to know the distribution `P(c|x)` (from image to latent code), which however is unknown.\n",
    "    * So instead they create `Q(c|x)`, which is an approximation of `P(c|x)`.\n",
    "    * `I(G(z, c); c)` is then computed using a lower bound maximization, similar to the one in variational autoencoders (called \"Variational Information Maximization\", hence the name \"InfoGAN\").\n",
    "    * Basic equation: `LowerBoundOfMutualInformation(G, Q) = E[log Q(c|x)] + H(c) <= I(G(z, c); c)`\n",
    "      * `c` is the latent code.\n",
    "      * `x` is the generated image.\n",
    "      * `H(c)` is the entropy of the latent codes (constant throughout the optimization).\n",
    "      * Optimization w.r.t. Q is done directly.\n",
    "      * Optimization w.r.t. G is done via the reparameterization trick.\n",
    "    * If `Q(c|x)` approximates `P(c|x)` *perfectly*, the lower bound becomes the mutual information (\"the lower bound becomes tight\").\n",
    "    * In practice, `Q(c|x)` is implemented as a neural network. Both Q and D have to process the generated images, which means that they can share many convolutional layers, significantly reducing the extra cost of training Q.\n",
    "\n",
    "* Results\n",
    "  * MNIST\n",
    "    * They use for `c` one categorical variable (10 values) and two continuous ones (uniform between -1 and +1).\n",
    "    * InfoGAN learns to associate the categorical one with the digit identity and the continuous ones with rotation and width.\n",
    "    * Applying Q(c|x) to an image and then classifying only on the categorical variable (i.e. fully unsupervised) yields 95% accuracy.\n",
    "    * Sampling new images with exaggerated continuous variables in the range `[-2,+2]` yields sound images (i.e. the network generalizes well).\n",
    "    * ![MNIST examples](images/InfoGAN__mnist.png?raw=true \"MNIST examples\")\n",
    "  * 3D face images\n",
    "    * InfoGAN learns to represent the faces via pose, elevation, lighting.\n",
    "    * They used five uniform variables for `c`. (So two of them apparently weren't associated with anything sensible? They are not mentioned.)\n",
    "  * 3D chair images\n",
    "    * InfoGAN learns to represent the chairs via identity (categorical) and rotation or width (apparently they did two experiments).\n",
    "    * They used one categorical variable (four values) and one continuous variable (uniform `[-1, +1]`).\n",
    "  * SVHN\n",
    "    * InfoGAN learns to represent lighting and to spot the center digit.\n",
    "    * They used four categorical variables (10 values each) and two continuous variables (uniform `[-1, +1]`). (Again, a few variables were apparently not associated with anything sensible?)\n",
    "  * CelebA\n",
    "    * InfoGAN learns to represent pose, presence of sunglasses (not perfectly), hair style and emotion (in the sense of \"smiling or not smiling\").\n",
    "    * They used 10 categorical variables (10 values each). (Again, a few variables were apparently not associated with anything sensible?)\n",
    "    * ![CelebA examples](images/InfoGAN__celeba.png?raw=true \"CelebA examples\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
